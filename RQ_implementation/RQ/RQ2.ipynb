{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7c12aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc7fb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import mplcursors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e27e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def norm_min_max(df: pd.DataFrame, col: str):\n",
    "    values = df[col]\n",
    "    return (values - values.min()) / (values.max() - values.min())\n",
    "\n",
    "\n",
    "def load_task_and_preprocess(results_file, task_name):\n",
    "\n",
    "    with open(results_file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    list_json = []\n",
    "    for l in lines:\n",
    "        list_json.append(json.loads(l))\n",
    "    df = pd.DataFrame(list_json)\n",
    "\n",
    "    acc_keys = {\"livecodebench\": \"acc\", \"code2text_python\": \"smoothed_bleu_4,create_output\"}\n",
    "    df = df[df[\"task_name\"] == task_name]\n",
    "    df[\"params\"] = df[\"model\"].apply(lambda x: re.findall(r\"(\\d+(?:\\.\\d+)?[bBmM])\", x.upper())[0])\n",
    "    df[\"acc_values\"] = df[\"acc_values\"].apply(lambda x: x[acc_keys[task_name]])\n",
    "    df = df.reset_index()\n",
    "    df[\"energy_norm\"] = norm_min_max(df, \"energy_consumed\")\n",
    "    df[\"ene_eff\"] = 1 - df[\"energy_norm\"]\n",
    "    df[\"perf\"] = norm_min_max(df, \"acc_values\")\n",
    "    df = df[[\"model\", \"params\", \"task_name\", \"acc_values\", \"perf\", \"energy_consumed\", \"ene_eff\"]]\n",
    "    return df\n",
    "\n",
    "df_lcb = load_task_and_preprocess(\"../../lm_eval/results/final_results.jsonl\", \"livecodebench\")\n",
    "df_c2t = load_task_and_preprocess(\"../../lm_eval/results/final_results.jsonl\", \"code2text_python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a48bf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm, LinearSegmentedColormap\n",
    "\n",
    "def point_creation():\n",
    "    n = 1600  # resolution\n",
    "    x = np.linspace(-0.1, 1.1, n)\n",
    "    y = np.linspace(-0.1, 1.1, n)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    return X, Y\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap, BoundaryNorm\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes  # optional\n",
    "from matplotlib import cm\n",
    "import matplotlib.patheffects as pe\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def gradient_labeling_two_side(classes_left, classes_right, df_left, df_right,\n",
    "                               filename, title_left=\"LiveCodeBench\", title_right=\"CodeXGLUE\", curve_plot=None, plot_title=None):\n",
    "    # discrete, print-friendly cmap\n",
    "    cmap = cm.get_cmap(\"YlGn\", 5)\n",
    "    norm = BoundaryNorm(np.arange(-0.5, 5.5, 1), cmap.N)\n",
    "\n",
    "    # side-by-side, shared y; tighter gap + room for bottom colorbar\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize=(11.2, 7.8))\n",
    "    fig.subplots_adjust(left=0.09, right=0.99, bottom=0.28, wspace=0.08)\n",
    "\n",
    "    if curve_plot is not None:\n",
    "        x_lcb, y_lcb, x_c2t, y_c2t = curve_plot\n",
    "        ax1.plot(x_lcb, y_lcb, c=\"#123455\", linewidth=2.4, linestyle=\"--\", label=\"Fitted Curve\")\n",
    "        ax1.legend()\n",
    "        if x_c2t is not None:\n",
    "            ax2.plot(x_c2t, y_c2t, c=\"#123455\", linewidth=2.4, linestyle=\"--\", label=\"Fitted Curve\")\n",
    "            ax2.legend()\n",
    "    # background fields\n",
    "    im1 = ax1.imshow(classes_left,  origin=\"lower\", extent=[-0.1, 1.1, -0.1, 1.1],\n",
    "                     cmap=cmap, norm=norm, interpolation=\"nearest\", rasterized=True)\n",
    "    im2 = ax2.imshow(classes_right, origin=\"lower\", extent=[-0.1, 1.1, -0.1, 1.1],\n",
    "                     cmap=cmap, norm=norm, interpolation=\"nearest\", rasterized=True)\n",
    "\n",
    "    # --- halo markers: white ring + dark core (high contrast everywhere)\n",
    "    def halo_scatter(ax, x, y):\n",
    "        ax.scatter(x, y, s=60, c=\"#0B2578\", marker=\"o\", linewidths=0, zorder=4)     # halo\n",
    "        sc = ax.scatter(x, y, s=24, c=\"#1a1a1a\", marker=\"o\",\n",
    "                   edgecolors=\"white\", linewidths=0.7, zorder=5)                   # core\n",
    "        return sc\n",
    "\n",
    "    first_scatter = halo_scatter(ax1, df_left[\"ene_eff\"],  df_left[\"perf\"])\n",
    "    second_scatter = halo_scatter(ax2, df_right[\"ene_eff\"], df_right[\"perf\"])\n",
    "\n",
    "    # labels, limits, titles\n",
    "    for ax in (ax1, ax2):\n",
    "        ax.set_xlim(-0.05, 1.05); ax.set_ylim(-0.05, 1.05)\n",
    "        ax.set_xlabel(\"Energy Efficiency\")\n",
    "        ax.spines[\"top\"].set_visible(False)\n",
    "        ax.spines[\"right\"].set_visible(False)\n",
    "    ax1.set_ylabel(\"Accuracy\")\n",
    "    ax1.set_title(title_left)\n",
    "    ax2.set_title(title_right)\n",
    "\n",
    "    # short horizontal colorbar under both plots\n",
    "    labels = [\"Very Weak\", \"Weak\", \"Moderate\", \"Strong\", \"Very Strong\"]\n",
    "    cbar = fig.colorbar(im1, ax=[ax1, ax2], orientation=\"horizontal\",\n",
    "                        ticks=range(5), pad=0.14, shrink=0.7, fraction=0.18)\n",
    "    cbar.ax.set_xticklabels(labels, fontsize=9)\n",
    "    def annotate_params(ax, x, y, params):\n",
    "        for xi, yi, pi in zip(x, y, params):\n",
    "            ax.annotate(pi, (xi, yi),\n",
    "                        xytext=(5, 4), textcoords=\"offset points\",\n",
    "                        fontsize=5, color=\"black\", zorder=7,\n",
    "                        path_effects=[pe.withStroke(linewidth=2.2, foreground=\"white\")])\n",
    "    annotate_params(ax1, df_left[\"ene_eff\"],  df_left[\"perf\"],  df_left[\"params\"])\n",
    "    annotate_params(ax2, df_right[\"ene_eff\"], df_right[\"perf\"], df_right[\"params\"])\n",
    "    \n",
    "    if plot_title is not None:\n",
    "        fig.suptitle(plot_title, fontsize=16, y=0.98)\n",
    "    plt.savefig(f\"{filename}.pdf\", bbox_inches=\"tight\", dpi=400)\n",
    "    return first_scatter, second_scatter\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82eeb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm, LinearSegmentedColormap\n",
    "\n",
    "\n",
    "def calculate_euc_formula(df):\n",
    "    df[\"distance\"] = ((1 - df[\"perf\"]) ** 2 + (1 - df[\"ene_eff\"]) ** 2) ** 0.5\n",
    "    df[\"distance_rank\"] = 0\n",
    "\n",
    "def fill_distance_ranking(df):\n",
    "    # Circle parameters\n",
    "    radiuses = np.linspace(0, np.sqrt(2), 6)\n",
    "    selected_so_far = set()\n",
    "    curr_rank = 5\n",
    "    for r in radiuses:\n",
    "        if r == 0:\n",
    "            continue\n",
    "        # Generate points on the circle\n",
    "        theta = np.linspace(0, 2 * np.pi, 100)\n",
    "        x = center[0] + r * np.cos(theta)\n",
    "        y = center[1] + r * np.sin(theta)\n",
    "        less_than_r = df[df[\"distance\"] < r].index.to_list()\n",
    "        new_points = set(less_than_r).difference(selected_so_far)\n",
    "        selected_so_far.update(less_than_r)\n",
    "        if new_points:\n",
    "            df.loc[list(new_points), \"distance_rank\"] = curr_rank\n",
    "        else:\n",
    "            # plt.scatter([], [])\n",
    "            pass\n",
    "        curr_rank -= 1\n",
    "\n",
    "def distance_base_class_calc():\n",
    "    X, Y = point_creation()\n",
    "    val = ((X - center[0]) ** 2 + (Y - center[1]) ** 2) ** 0.5\n",
    "    classes = np.ceil((val) / (np.sqrt(2) / 5))\n",
    "    classes[classes <= 0] = 1\n",
    "    classes[classes > 5] = 5\n",
    "    classes -= 1\n",
    "    classes -= 4\n",
    "    classes = np.abs(classes)\n",
    "\n",
    "    return classes\n",
    "\n",
    "\n",
    "\n",
    "def distance_based_computation(df_lcb, df_c2t):\n",
    "    calculate_euc_formula(df_lcb)\n",
    "    calculate_euc_formula(df_c2t)\n",
    "\n",
    "    fill_distance_ranking(df_lcb)\n",
    "    fill_distance_ranking(df_c2t)\n",
    "\n",
    "    classes = distance_base_class_calc()\n",
    "    \n",
    "    gradient_labeling_two_side(classes, classes, df_lcb, df_c2t, filename=\"distance_based\")\n",
    "\n",
    "\n",
    "center = (1, 1)\n",
    "distance_based_computation(df_lcb, df_c2t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8183db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.covariance import MinCovDet\n",
    "from scipy.stats import chi2\n",
    "\n",
    "def remove_outliers(df):\n",
    "\n",
    "    X = df[[\"ene_eff\", \"perf\"]].to_numpy()\n",
    "    mcd = MinCovDet().fit(X)\n",
    "    D2 = mcd.mahalanobis(X)\n",
    "    cut = chi2.ppf(0.95, df=2)\n",
    "\n",
    "    outliers = D2 > cut\n",
    "    inliers = ~outliers\n",
    "    X_clean = X[inliers]\n",
    "    plt.figure(figsize=(5, 2))\n",
    "    plt.scatter(X_clean[:, 0], X_clean[:, 1])\n",
    "    plt.scatter(X[:, 0], X[:, 1], marker=\"x\", s=12)\n",
    "    return X_clean\n",
    "\n",
    "X_clean_lcb = remove_outliers(df_lcb)\n",
    "X_clean_c2t = remove_outliers(df_c2t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c687b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_all_possible_derivatives(ene_eff, acc):\n",
    "    derivatives = []\n",
    "    for i in range(len(ene_eff)):\n",
    "        i_x = ene_eff[i]\n",
    "        i_y = acc[i]\n",
    "        for j in range(i+1, len(ene_eff)):\n",
    "            new_x = ene_eff[j]\n",
    "            new_y = acc[j]\n",
    "            if (new_x < i_x and new_y > i_y) or (new_x > i_x and new_y < i_y):\n",
    "                derivatives.append(-abs((new_y - i_y) / (new_x - i_x)))\n",
    "    return derivatives\n",
    "all_possible_derivates_lcb = create_all_possible_derivatives(df_lcb[\"ene_eff\"], df_lcb[\"perf\"])\n",
    "all_possible_derivates_c2t = create_all_possible_derivatives(df_c2t[\"ene_eff\"], df_c2t[\"perf\"])\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.covariance import MinCovDet\n",
    "from scipy.stats import chi2\n",
    "\n",
    "def remove_derivative_outliers(all_possible_derivates):\n",
    "\n",
    "    deriv = np.array(all_possible_derivates)\n",
    "    mcd = MinCovDet().fit(deriv.reshape(-1, 1))\n",
    "    # squared Mahalanobis distances under robust location/covariance:\n",
    "    d2 = mcd.mahalanobis(deriv.reshape(-1, 1))\n",
    "\n",
    "    thr = chi2.ppf(0.95, df=1)\n",
    "\n",
    "    deriv_inliers_all = deriv[d2 <= thr]\n",
    "    deriv_outliers_all = deriv[d2 > thr]\n",
    "    return deriv_inliers_all\n",
    "\n",
    "deriv_inliers_all_lcb = remove_derivative_outliers(all_possible_derivates_lcb)\n",
    "deriv_inliers_all_c2t = remove_derivative_outliers(all_possible_derivates_c2t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c2cc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def approximate_regression_function(df, X_clean, task_name, deriv_inliers_all):\n",
    "\n",
    "    x_raw, y = X_clean[:, 0], X_clean[:, 1]\n",
    "\n",
    "    degree_dict = {\"livecodebench\": 5, \"code2text_python\": 5}\n",
    "\n",
    "    d = degree_dict[task_name]\n",
    "    b = cp.Variable(d + 1)\n",
    "\n",
    "    # Least-squares objective\n",
    "    x_transformed = np.vander(x_raw, N=d + 1, increasing=True)\n",
    "    objective = cp.Minimize(cp.sum_squares(x_transformed @ b - y))\n",
    "\n",
    "    # Enforce f′(z) ≤ 0 on a grid\n",
    "    z = np.linspace(0, 1, 50)\n",
    "    D = np.zeros((len(z), d + 1))\n",
    "    for j, zj in enumerate(z):\n",
    "        for k in range(1, d + 1):\n",
    "            D[j, k] = k * zj ** (k - 1)\n",
    "        \n",
    "    constraints = {\n",
    "        \"livecodebench\": [D @ b <= np.percentile(deriv_inliers_all, 75), cp.sum(b) >= 1e-2],\n",
    "        \"code2text_python\": [D @ b <= np.percentile(deriv_inliers_all, 75), cp.sum(b) >= 1e-2],\n",
    "    }\n",
    "    # the second constraint is for ensuring that plot lies above 0\n",
    "    prob = cp.Problem(objective, constraints[task_name])\n",
    "    prob.solve()\n",
    "\n",
    "    # below this for plotting\n",
    "    X_plot = np.linspace(-0.1, 1.1, 100).reshape(-1, 1)\n",
    "    X_grid = np.vander(X_plot.flatten(), N=d + 1, increasing=True)\n",
    "    y_grid = X_grid @ b.value\n",
    "\n",
    "    plt.figure(figsize=(5, 3))\n",
    "    plt.scatter(X_clean[:, 0], X_clean[:, 1], s=30)\n",
    "    plt.scatter(df[\"ene_eff\"], df[\"perf\"], c=\"red\", marker=\"x\", s=8)\n",
    "    plt.plot(X_plot, y_grid, label=\"monotone ↓\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.title(\"Smooth Monotonic-Decreasing Regression\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return b, d\n",
    "\n",
    "coefficients_lcb, degree_lcb = approximate_regression_function(df_lcb, X_clean_lcb, \"livecodebench\", deriv_inliers_all_lcb)\n",
    "coefficients_c2t, degree_c2t = approximate_regression_function(df_c2t, X_clean_c2t, \"code2text_python\", deriv_inliers_all_c2t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9d21c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_rank(df, b, d):\n",
    "    df[\"predicted_perf\"] = np.vander(df[\"ene_eff\"], N=d + 1, increasing=True) @ b.value\n",
    "    df[\"score\"] = df[\"perf\"] / df[\"predicted_perf\"]\n",
    "    min_score, max_score = df[\"score\"].min(), df[\"score\"].max()\n",
    "    five_intervals = (max_score - min_score) / 5\n",
    "    df[\"regression_rank\"] = np.ceil((df[\"score\"] - min_score) / five_intervals)\n",
    "    df.loc[df[\"regression_rank\"] == 0, \"regression_rank\"] = 1\n",
    "    df[\"regression_rank\"] = df[\"regression_rank\"].astype(int)\n",
    "    return min_score, five_intervals\n",
    "\n",
    "\n",
    "min_score_lcb, five_interval_lcb = regression_rank(df_lcb, coefficients_lcb, degree_lcb)\n",
    "min_score_c2t, five_interval_c2t = regression_rank(df_c2t, coefficients_c2t, degree_c2t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e1aa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm, LinearSegmentedColormap\n",
    "\n",
    "def draw_curve(d, b):\n",
    "    X_plot = np.linspace(-0.1, 1.1, 100).reshape(-1, 1)\n",
    "    X_grid = np.vander(X_plot.flatten(), N=d + 1, increasing=True)\n",
    "    y_grid = X_grid @ b.value\n",
    "    return X_plot, y_grid\n",
    "\n",
    "def regression_class_computation(d, b, min_score, five_intervals):\n",
    "    X, Y = point_creation()\n",
    "    deg = np.arange(d + 1)  # 0..d\n",
    "    # any real-valued function\n",
    "    val = Y / ((X[..., None] ** deg) @ b.value)\n",
    "    # ----- 3) bin into at most 5 classes -----\n",
    "    classes = np.ceil((val - min_score) / five_intervals)\n",
    "    classes[classes <= 0] = 1\n",
    "    classes[classes > 5] = 5\n",
    "    classes -= 1\n",
    "    return classes\n",
    "\n",
    "\n",
    "def regression_computation(\n",
    "    df_lcb,\n",
    "    coefficients_lcb,\n",
    "    min_score_lcb,\n",
    "    five_interval_lcb,\n",
    "    degree_lcb,\n",
    "    df_c2t,\n",
    "    coefficients_c2t,\n",
    "    min_score_c2t,\n",
    "    five_interval_c2t,\n",
    "    degree_c2t,\n",
    "):\n",
    "    lcb_classes = regression_class_computation(degree_lcb, coefficients_lcb, min_score_lcb, five_interval_lcb)\n",
    "    c2t_classes = regression_class_computation(degree_c2t, coefficients_c2t, min_score_c2t, five_interval_c2t)\n",
    "\n",
    "    x_lcb, y_lcb = draw_curve(degree_lcb, coefficients_lcb)\n",
    "    x_c2t, y_c2t = draw_curve(degree_c2t, coefficients_c2t)\n",
    "    sc1, sc2 = gradient_labeling_two_side(\n",
    "        lcb_classes,\n",
    "        c2t_classes,\n",
    "        df_lcb,\n",
    "        df_c2t,\n",
    "        \"regression_curve\",\n",
    "        curve_plot=(x_lcb, y_lcb, x_c2t, y_c2t),\n",
    "    )\n",
    "    return sc1, sc2\n",
    "\n",
    "\n",
    "sc1, sc2 = regression_computation(df_lcb,\n",
    "    coefficients_lcb,\n",
    "    min_score_lcb,\n",
    "    five_interval_lcb,\n",
    "    degree_lcb,\n",
    "    df_c2t,\n",
    "    coefficients_c2t,\n",
    "    min_score_c2t,\n",
    "    five_interval_c2t,\n",
    "    degree_c2t)\n",
    "\n",
    "\n",
    "def regression_on_hover(df):\n",
    "    def on_add(sel):\n",
    "        idx = sel.index  # index of the point\n",
    "        sample = df.iloc[idx]\n",
    "        annotation_text = f\"model name: {sample['model'].split('/')[1]}\\nactual performance: {sample['perf']:.2f}\\nexpected performance: {sample['predicted_perf']:.2f}\\nscore: {(sample['score']):.2f}\\nregression_rank: {sample['regression_rank']}\"\n",
    "        sel.annotation.set_text(annotation_text)\n",
    "        bbox = sel.annotation.get_bbox_patch()\n",
    "        bbox.set_facecolor(\"blue\")\n",
    "        bbox.set_alpha(0.9)  # make it more opaque\n",
    "        bbox.set_boxstyle(\"round,pad=0.5\")\n",
    "\n",
    "        # set the annotation’s text color directly\n",
    "        sel.annotation.set_color(\"white\")\n",
    "        # if you want to adjust font size:\n",
    "        sel.annotation.set_fontsize(8)\n",
    "    return on_add\n",
    "\n",
    "cursor1 = mplcursors.cursor(sc1, hover=True)\n",
    "cursor2 = mplcursors.cursor(sc2, hover=True)\n",
    "cursor1.connect(\"add\", regression_on_hover(df_lcb))\n",
    "cursor2.connect(\"add\", regression_on_hover(df_c2t))\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d8b515",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_comparison(degree, coefficients, min_score, five_interval, df, file_name, plot_title):\n",
    "    regression_classes = regression_class_computation(degree, coefficients, min_score, five_interval)\n",
    "    distance_classes = distance_base_class_calc()\n",
    "\n",
    "    x_lcb, y_lcb = draw_curve(degree, coefficients)\n",
    "    sc1, sc2 = gradient_labeling_two_side(\n",
    "        regression_classes,\n",
    "        distance_classes,\n",
    "        df,\n",
    "        df,\n",
    "        file_name,\n",
    "        curve_plot=(x_lcb, y_lcb, None, None),\n",
    "        title_left=\"OTE\",\n",
    "        title_right=\"COC\",\n",
    "        plot_title=plot_title\n",
    "    )\n",
    "    return sc1, sc2\n",
    "\n",
    "metric_comparison(degree_lcb, coefficients_lcb, min_score_lcb, five_interval_lcb, df_lcb, \"lcb_metric_comparison\", \"LiveCodeBench\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8964c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_comparison(degree_c2t, coefficients_c2t, min_score_c2t, five_interval_c2t, df_c2t, \"c2t_metric_comparison\", \"CodeXGLUE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab20628f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import BoundaryNorm\n",
    "import matplotlib.patheffects as pe  # ensure this import exists for annotations\n",
    "\n",
    "def gradient_labeling_2x2(classes_tl, classes_tr, classes_bl, classes_br,\n",
    "                          df_tl, df_tr, df_bl, df_br,\n",
    "                          filename,\n",
    "                          title_tl=\"LiveCodeBench\", title_tr=\"CodeXGLUE\",\n",
    "                          title_bl=\"Dataset C\", title_br=\"Dataset D\",\n",
    "                          curve_plot=None, plot_title=None):\n",
    "    \n",
    "    fontsize_annotation = 9\n",
    "    fontsize_label = 16\n",
    "    # --- colormap (unchanged) ---\n",
    "\n",
    "    cmap = cm.get_cmap(\"YlGn\", 5)\n",
    "    norm = BoundaryNorm(np.arange(-0.5, 5.5, 1), cmap.N)\n",
    "\n",
    "    # --- 2x2 grid, shared axes; leave room for bottom colorbar ---\n",
    "    fig, axs = plt.subplots(2, 2, sharex=True, sharey=True, figsize=(9, 9), layout=\"compressed\")\n",
    "    # fig.get_layout_engine().set(w_pad=4 / 72, h_pad=4 / 72, hspace=0,\n",
    "    #                         wspace=0)\n",
    "\n",
    "    ax_tl, ax_tr = axs[0, 0], axs[0, 1]\n",
    "    ax_bl, ax_br = axs[1, 0], axs[1, 1]\n",
    "\n",
    "    # --- optional fitted curves ---\n",
    "    # If provided for all four: (x_tl, y_tl, x_tr, y_tr, x_bl, y_bl, x_br, y_br)\n",
    "    # If provided for top row only: (x_tl, y_tl, x_tr, y_tr)\n",
    "    if curve_plot is not None:\n",
    "        try:\n",
    "            x_tl, y_tl, x_tr, y_tr, x_bl, y_bl, x_br, y_br = curve_plot\n",
    "            for ax, (x, y) in zip([ax_tl, ax_tr, ax_bl, ax_br],\n",
    "                                  [(x_tl, y_tl), (x_tr, y_tr), (x_bl, y_bl), (x_br, y_br)]):\n",
    "                ax.plot(x, y, c=\"#123455\", linewidth=2.4, linestyle=\"--\", label=\"Fitted Curve\")\n",
    "                ax.legend()\n",
    "        except ValueError:\n",
    "            x_tl, y_tl, x_tr, y_tr = curve_plot\n",
    "            for ax, (x, y) in zip([ax_tl, ax_tr], [(x_tl, y_tl), (x_tr, y_tr)]):\n",
    "                ax.plot(x, y, c=\"#123455\", linewidth=2.4, linestyle=\"--\", label=\"Fitted Curve\")\n",
    "                ax.legend()\n",
    "\n",
    "    # --- backgrounds (all share SAME cmap/norm) ---\n",
    "    im_tl = ax_tl.imshow(classes_tl, origin=\"lower\", extent=[-0.1, 1.1, -0.1, 1.1],\n",
    "                         cmap=cmap, norm=norm, interpolation=\"nearest\", rasterized=True)\n",
    "    ax_tr.imshow(classes_tr, origin=\"lower\", extent=[-0.1, 1.1, -0.1, 1.1],\n",
    "                 cmap=cmap, norm=norm, interpolation=\"nearest\", rasterized=True)\n",
    "    ax_bl.imshow(classes_bl, origin=\"lower\", extent=[-0.1, 1.1, -0.1, 1.1],\n",
    "                 cmap=cmap, norm=norm, interpolation=\"nearest\", rasterized=True)\n",
    "    ax_br.imshow(classes_br, origin=\"lower\", extent=[-0.1, 1.1, -0.1, 1.1],\n",
    "                 cmap=cmap, norm=norm, interpolation=\"nearest\", rasterized=True)\n",
    "\n",
    "    # --- halo markers (unchanged style) ---\n",
    "    def halo_scatter(ax, x, y):\n",
    "        ax.scatter(x, y, s=60, c=\"#0B2578\", marker=\"o\", linewidths=0, zorder=4)     # halo\n",
    "        return ax.scatter(x, y, s=24, c=\"#1a1a1a\", marker=\"o\",\n",
    "                          edgecolors=\"white\", linewidths=0.7, zorder=5)\n",
    "\n",
    "    sc_tl = halo_scatter(ax_tl, df_tl[\"ene_eff\"], df_tl[\"perf\"])\n",
    "    sc_tr = halo_scatter(ax_tr, df_tr[\"ene_eff\"], df_tr[\"perf\"])\n",
    "    sc_bl = halo_scatter(ax_bl, df_bl[\"ene_eff\"], df_bl[\"perf\"])\n",
    "    sc_br = halo_scatter(ax_br, df_br[\"ene_eff\"], df_br[\"perf\"])\n",
    "\n",
    "\n",
    "\n",
    "    # --- limits, spines, titles ---\n",
    "    for ax in (ax_tl, ax_tr, ax_bl, ax_br):\n",
    "        ax.set_xlim(-0.05, 1.05); ax.set_ylim(-0.05, 1.05)\n",
    "        ax.spines[\"top\"].set_visible(False)\n",
    "        ax.spines[\"right\"].set_visible(False)\n",
    "        # clear labels; we'll set only for bottom-left\n",
    "        ax.set_xlabel(\"\")\n",
    "        ax.set_ylabel(\"\")\n",
    "\n",
    "    for ax in (ax_tl, ax_tr, ax_bl, ax_br):\n",
    "        ax.xaxis.set_ticks(np.linspace(0, 1, 6))  # 6 evenly spaced ticks from 0 to 1\n",
    "        ax.yaxis.set_ticks(np.linspace(0, 1, 6))  # match y-axis ticks if you want symmetry\n",
    "        ax.tick_params(axis='both', labelsize=15)\n",
    "\n",
    "\n",
    "    ax_tl.set_title(title_tl, fontsize=fontsize_label, fontweight=\"bold\")\n",
    "    ax_tr.set_title(title_tr, fontsize=fontsize_label, fontweight=\"bold\")\n",
    "    ax_bl.set_title(title_bl, fontsize=fontsize_label, fontweight=\"bold\")\n",
    "    ax_br.set_title(title_br, fontsize=fontsize_label, fontweight=\"bold\")\n",
    "\n",
    "    ax_bl.set_xlabel(\"Energy Efficiency\", fontsize=fontsize_label)\n",
    "    ax_bl.set_ylabel(\"Accuracy\", fontsize=fontsize_label)\n",
    "    ax_br.set_xlabel(\"Energy Efficiency\", fontsize=fontsize_label)\n",
    "    ax_tl.set_ylabel(\"Accuracy\", fontsize=fontsize_label)\n",
    "\n",
    "    \n",
    "\n",
    "    # --- parameter annotations (unchanged) ---\n",
    "    def annotate_params(ax, x, y, params):\n",
    "        for xi, yi, pi in zip(x, y, params):\n",
    "            ax.annotate(pi, (xi, yi),\n",
    "                        xytext=(5, 4), textcoords=\"offset points\",\n",
    "                        fontsize=fontsize_annotation, color=\"black\", zorder=7,\n",
    "                        path_effects=[pe.withStroke(linewidth=2.2, foreground=\"white\")])\n",
    "\n",
    "\n",
    "    annotate_params(ax_tl, df_tl[\"ene_eff\"], df_tl[\"perf\"], [str(i+1) for i in range(len(df_tl))])\n",
    "    annotate_params(ax_tr, df_tr[\"ene_eff\"], df_tr[\"perf\"], [str(i+1) for i in range(len(df_tl))])\n",
    "    annotate_params(ax_bl, df_bl[\"ene_eff\"], df_bl[\"perf\"], [str(i+1) for i in range(len(df_tl))])\n",
    "    annotate_params(ax_br, df_br[\"ene_eff\"], df_br[\"perf\"], [str(i+1) for i in range(len(df_tl))])\n",
    "\n",
    "    # --- single shared horizontal colorbar (same look as before) ---\n",
    "    labels = [\"Weakest (1)\", \"Weak (2)\", \"Moderate (3)\", \"Strong (4)\", \"Strongest (5)\"]\n",
    "    cbar = fig.colorbar(im_tl, ax=axs.ravel(), orientation=\"horizontal\",\n",
    "                        ticks=range(5), pad=0.03)\n",
    "    \n",
    "    cbar.ax.set_xticklabels(labels, fontsize=13.5, fontweight=\"bold\")\n",
    "\n",
    "    # for ax in axs.ravel():\n",
    "    #     ax.set_aspect('equal')\n",
    "    # plt.tight_layout()\n",
    "    \n",
    "\n",
    "    if plot_title is not None:\n",
    "        fig.suptitle(plot_title, fontsize=16, y=0.98)\n",
    "\n",
    "    plt.savefig(f\"{filename}.pdf\", bbox_inches=\"tight\", dpi=400)\n",
    "    return sc_tl, sc_tr, sc_bl, sc_br\n",
    "\n",
    "\n",
    "def metric_comparison(degree, coefficients, min_score, five_interval, df, file_name, plot_title):\n",
    "    regression_classes = regression_class_computation(degree, coefficients, min_score, five_interval)\n",
    "    distance_classes = distance_base_class_calc()\n",
    "\n",
    "    x_lcb, y_lcb = draw_curve(degree, coefficients)\n",
    "    sc1, sc2 = gradient_labeling_two_side(\n",
    "        regression_classes,\n",
    "        distance_classes,\n",
    "        df,\n",
    "        df,\n",
    "        file_name,\n",
    "        curve_plot=(x_lcb, y_lcb, None, None),\n",
    "        title_left=\"OTE\",\n",
    "        title_right=\"COC\",\n",
    "        plot_title=plot_title\n",
    "    )\n",
    "    return sc1, sc2\n",
    "regression_classes_lcb = regression_class_computation(degree_lcb, coefficients_lcb, min_score_lcb, five_interval_lcb)\n",
    "x_lcb, y_lcb = draw_curve(degree_lcb, coefficients_lcb)\n",
    "regression_classes_c2t = regression_class_computation(degree_c2t, coefficients_c2t, min_score_c2t, five_interval_c2t)\n",
    "x_c2t, y_c2t = draw_curve(degree_c2t, coefficients_c2t)\n",
    "distance_classes = distance_base_class_calc()\n",
    "\n",
    "gradient_labeling_2x2(regression_classes_lcb, regression_classes_c2t, distance_classes, distance_classes, df_lcb, df_c2t, df_lcb, df_c2t, \"all_in_one\", curve_plot=(x_lcb, y_lcb, x_c2t, y_c2t), title_bl=\"LiveCodeBench-CIRC\", title_br=\"CodeXGLUE-CIRC\", title_tl=\"LiveCodeBench-OTER\", title_tr=\"CodeXGLUE-OTER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2edabbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lcb.drop(columns=\"predicted_perf\").to_excel(f\"livecodebench_rating.xlsx\")\n",
    "# df_lcb.drop(columns=\"predicted_perf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7886912",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c2t.drop(columns=\"predicted_perf\").to_excel(f\"code2text_python_rating.xlsx\")\n",
    "# df_c2t.drop(columns=\"predicted_perf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461fbfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(df_lcb, df_c2t, on=\"model\", how=\"inner\")\n",
    "merged_df.columns = [x.replace(\"_x\", \"_lcb\") if x[-1] == \"x\" else x.replace(\"_y\", \"_c2t\") for x in merged_df.columns]\n",
    "merged_df = merged_df.drop(columns=[\"task_name_lcb\", \"task_name_c2t\", \"params_c2t\", \"predicted_perf_lcb\", \"predicted_perf_c2t\"]).rename(columns={\"params_lcb\": \"params\"})\n",
    "merged_df.to_excel(\"all_results.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6140a625",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as pe\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "\n",
    "def plot_two_score_bars(\n",
    "    df,\n",
    "    model_col=\"model\",\n",
    "    score_cols=(\"distance_rank_lcb\", \"regression_rank_lcb\"),\n",
    "    titles=None,\n",
    "    sort_by=\"mean\",                     # \"mean\", score_cols[0], or score_cols[1]\n",
    "    title=\"Model Scores\",\n",
    "    filename=\"scores_pretty.pdf\",\n",
    "):\n",
    "    a_col, b_col = score_cols\n",
    "    m2id = {df.iloc[id][\"model\"].split(\"/\")[1]: id for id in range(len(df))}\n",
    "    # ---- order rows (optional) ----\n",
    "    if sort_by == \"mean\":\n",
    "        order = (df[[a_col, b_col]].mean(axis=1)).argsort()[::-1]\n",
    "    elif sort_by in score_cols:\n",
    "        order = df[sort_by].argsort()[::-1]\n",
    "    else:\n",
    "        order = np.arange(len(df))\n",
    "    d = df.iloc[order].reset_index(drop=True)\n",
    "    d[model_col] = d[model_col].apply(lambda x: x.split(\"/\")[1])\n",
    "    models = d[model_col].astype(str).values\n",
    "    A = d[a_col].astype(float).values\n",
    "    B = d[b_col].astype(float).values\n",
    "\n",
    "    # ---- layout ----\n",
    "    x = np.arange(len(models))\n",
    "    h = 0.38       \n",
    "    fig, ax = plt.subplots(figsize=(10, 4))\n",
    "\n",
    "    # ---- colors (kept) ----\n",
    "    col_a = \"#065C48\"\n",
    "    col_b = \"#A7D500\"\n",
    "\n",
    "    # ---- bars (grouped, vertical) ----\n",
    "    bar_a = ax.bar(x - h/2, A, width=h, color=col_a, edgecolor=\"#2b2b2b\",\n",
    "                   linewidth=0.6, label=titles[0])\n",
    "    bar_b = ax.bar(x + h/2, B, width=h, color=col_b, edgecolor=\"#2b2b2b\",\n",
    "                   linewidth=0.6, label=titles[1], hatch=\"//\")\n",
    "\n",
    "    # ---- value labels (removed) ----\n",
    "    # (no annotations on top of bars)\n",
    "\n",
    "    # ---- axes, ticks, grid ----\n",
    "    ax.set_xticks(x)\n",
    "    # ax.set_xticklabels([\"$\\\\text{M}_{\" + str(m2id[m] + 1) + \"}$\" for m in models], ha=\"center\", rotation=45, fontsize=13.5) \n",
    "    ax.set_xticklabels([\"M\" + str(m2id[m] + 1) for m in models], ha=\"center\", rotation=45, fontsize=14.5) \n",
    "    # ax.set_xlabel(\"Model\")\n",
    "    ax.set_ylabel(\"Rate\", fontsize=20)\n",
    "    ax.set_yticklabels([i-1 for i in range(7)], fontsize=17)\n",
    "    y_max = max(A.max(), B.max())\n",
    "    ax.set_ylim(0, y_max * 1.10)\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(1)) \n",
    "    ax.grid(axis=\"y\", linestyle=\"--\", alpha=0.25)\n",
    "\n",
    "    # clean frame\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "    # legend above, centered (kept)\n",
    "    # ax.legend(frameon=False, ncol=2, loc=\"lower center\",\n",
    "    #           bbox_to_anchor=(0.5, 1.02), borderaxespad=0)\n",
    "    ax.legend(fontsize=17)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(filename, bbox_inches=\"tight\", dpi=400)\n",
    "\n",
    "\n",
    "plot_two_score_bars(merged_df, model_col=\"model\", score_cols=(\"distance_rank_lcb\",\"regression_rank_lcb\"),\n",
    "                    titles=(\"LiveCodeBench-CIRC\", \"LiveCodeBench-OTER\"), title=\"Model Scores\", sort_by=\"mean\", filename=\"lcb_scores_comparison.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bf6b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "[\"$\\text{M}_{\" + str(i+1) + \"}$\" for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa1a6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_two_score_bars(merged_df, model_col=\"model\", score_cols=(\"distance_rank_lcb\",\"distance_rank_c2t\"),\n",
    "                    titles=(\"LiveCodeBench-CIRC\", \"CodeXGLUE-CIRC\"), title=\"Model Scores\", sort_by=\"mean\", filename=\"scores_distance_comparison.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb683dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_two_score_bars(merged_df, model_col=\"model\", score_cols=(\"regression_rank_lcb\",\"regression_rank_c2t\"),\n",
    "                    titles=(\"LiveCodeBench-OTER\", \"CodeXGLUE-OTER\"), title=\"Model Scores\", sort_by=\"mean\", filename=\"scores_regression_comparison.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8909be30",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_two_score_bars(merged_df, model_col=\"model\", score_cols=(\"distance_rank_c2t\",\"regression_rank_c2t\"),\n",
    "                    titles=(\"CodeXGLUE-CIRC\", \"CodeXGLUE-OTER\"), title=\"Model Scores\", sort_by=\"mean\", filename=\"c2t_scores_comparison.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94b4d3d",
   "metadata": {},
   "source": [
    "### Until Here, the rest are some random experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f41f9f",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
